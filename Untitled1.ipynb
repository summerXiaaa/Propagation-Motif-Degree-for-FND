{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2460c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 1 ----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 加载数据\n",
    "r = pd.read_csv('E:/6个数据集数据汇总/weibo_rumor_all.csv')\n",
    "t = pd.read_csv('E:/6个数据集数据汇总/weibo_true_all.csv')\n",
    "r['label'] = 1\n",
    "t['label'] = 0\n",
    "df = pd.concat([t, r], ignore_index=True)\n",
    "\n",
    "# 特征归一化\n",
    "df1 = df.iloc[:, 2:-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df7 = df1[['m3_1', 'm3_2', 'm4_1', 'm4_2', \n",
    "           'm4_3', 'm4_4', 'm5_1', 'm5_2', \n",
    "           'm5_3', 'm5_4', 'm5_5', 'm5_6', \n",
    "           'm5_7', 'm5_8', 'm5_9']]\n",
    "label = df['label']\n",
    "\n",
    "# 初始化结果列表\n",
    "results = []\n",
    "\n",
    "# 多轮实验\n",
    "for iteration in range(50):\n",
    "    print(f'---------- Iteration {iteration+1} ----------')\n",
    "    \n",
    "    # 划分训练与测试集\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df7, label, test_size=0.2, stratify=label, random_state=iteration)\n",
    "\n",
    "    # 不做过采样，直接用原始训练集计算 scale_pos_weight\n",
    "    scale_weight = train_y.value_counts()[0] / train_y.value_counts()[1]\n",
    "\n",
    "    # 超参数网格\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 150],\n",
    "        'max_depth': [6,8,10],\n",
    "        'min_child_weight': [1, 2, 4],\n",
    "        'learning_rate': [0.01,0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0]\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_weight\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=iteration)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    grid.fit(train_x, train_y)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(test_x)\n",
    "\n",
    "    results.append({\n",
    "        'Iteration': iteration + 1,\n",
    "        'Accuracy': round(accuracy_score(test_y, y_pred), 3),\n",
    "        'Recall': round(recall_score(test_y, y_pred), 3),\n",
    "        'F1 Score': round(f1_score(test_y, y_pred), 3),\n",
    "        'Precision': round(precision_score(test_y, y_pred), 3),\n",
    "        'Best Params': grid.best_params_\n",
    "    })\n",
    "\n",
    "# 保存结果\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('MMTD_results_weighted_no_oversample_5fold.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa7b576-6bb4-44a4-a347-a75fe668d42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 1 ----------\n",
      "---------- Iteration 2 ----------\n",
      "---------- Iteration 3 ----------\n",
      "---------- Iteration 4 ----------\n",
      "---------- Iteration 5 ----------\n",
      "---------- Iteration 6 ----------\n",
      "---------- Iteration 7 ----------\n",
      "---------- Iteration 8 ----------\n",
      "---------- Iteration 9 ----------\n",
      "---------- Iteration 10 ----------\n",
      "---------- Iteration 11 ----------\n",
      "---------- Iteration 12 ----------\n",
      "---------- Iteration 13 ----------\n",
      "---------- Iteration 14 ----------\n",
      "---------- Iteration 15 ----------\n",
      "---------- Iteration 16 ----------\n",
      "---------- Iteration 17 ----------\n",
      "---------- Iteration 18 ----------\n",
      "---------- Iteration 19 ----------\n",
      "---------- Iteration 20 ----------\n",
      "CPU times: total: 35.1 s\n",
      "Wall time: 9min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 加载数据\n",
    "r1 = pd.read_csv('E:/6个数据集数据汇总/politifact_fake.csv')\n",
    "t = pd.read_csv('E:/6个数据集数据汇总/politifact_real.csv')\n",
    "r = r1.iloc[:220]\n",
    "\n",
    "r['label'] = 1\n",
    "t['label'] = 0\n",
    "df = pd.concat([t, r], ignore_index=True)\n",
    "\n",
    "# 特征归一化\n",
    "df1 = df.iloc[:, 2:-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df7 = df1[['m3_1', 'm3_2', 'm4_1', 'm4_2', \n",
    "           'm4_3', 'm4_4', 'm5_1', 'm5_2', \n",
    "           'm5_3', 'm5_4', 'm5_5', 'm5_6', \n",
    "           'm5_7', 'm5_8', 'm5_9']]\n",
    "label = df['label']\n",
    "\n",
    "# 初始化结果列表\n",
    "results = []\n",
    "# 多轮实验\n",
    "for iteration in range(20):\n",
    "    print(f'---------- Iteration {iteration+1} ----------')\n",
    "    \n",
    "    # 划分训练与测试集\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df7, label, test_size=0.2, stratify=label, random_state=iteration)\n",
    "\n",
    "    # 固定经验 scale_pos_weight\n",
    "    scale_weight = 5\n",
    "\n",
    "    # 扩大模型容量，加入正则项\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 300],\n",
    "        'max_depth': [5, 10],\n",
    "        'min_child_weight': [2, 4],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0],\n",
    "        'reg_alpha': [0.1, 1.0],\n",
    "        'scale_pos_weight': [scale_weight]\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=iteration)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',  # 改为准确率优化\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    grid.fit(\n",
    "        train_x, train_y\n",
    "       \n",
    "    )\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(test_x)\n",
    "\n",
    "    results.append({\n",
    "        'Iteration': iteration + 1,\n",
    "        'Accuracy': round(accuracy_score(test_y, y_pred), 3),\n",
    "        'Recall': round(recall_score(test_y, y_pred), 3),\n",
    "        'F1 Score': round(f1_score(test_y, y_pred), 3),\n",
    "        'Precision': round(precision_score(test_y, y_pred), 3),\n",
    "        'Best Params': grid.best_params_\n",
    "    })\n",
    "# 保存结果\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('MMTD_politifact_weighted_no_oversample_5fold1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac70109-6168-4a88-82db-307a7a13ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Iteration 1 ----------\n",
      "---------- Iteration 2 ----------\n",
      "---------- Iteration 3 ----------\n",
      "---------- Iteration 4 ----------\n",
      "---------- Iteration 5 ----------\n",
      "---------- Iteration 6 ----------\n",
      "---------- Iteration 7 ----------\n",
      "---------- Iteration 8 ----------\n",
      "---------- Iteration 9 ----------\n",
      "---------- Iteration 10 ----------\n",
      "---------- Iteration 11 ----------\n",
      "---------- Iteration 12 ----------\n",
      "---------- Iteration 13 ----------\n",
      "---------- Iteration 14 ----------\n",
      "---------- Iteration 15 ----------\n",
      "---------- Iteration 16 ----------\n",
      "---------- Iteration 17 ----------\n",
      "---------- Iteration 18 ----------\n",
      "---------- Iteration 19 ----------\n",
      "---------- Iteration 20 ----------\n",
      "CPU times: total: 22min 52s\n",
      "Wall time: 9min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 加载数据\n",
    "r = pd.read_csv('E:/6个数据集数据汇总/gossipcop_fake.csv')\n",
    "t = pd.read_csv('E:/6个数据集数据汇总/gossipcop_real.csv')\n",
    "r['label'] = 1\n",
    "t['label'] = 0\n",
    "df = pd.concat([t, r], ignore_index=True)\n",
    "\n",
    "# 特征归一化\n",
    "df1 = df.iloc[:, 2:-1].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df7 = df1[['m3_1', 'm3_2', 'm4_1', 'm4_2', \n",
    "           'm4_3', 'm4_4', 'm5_1', 'm5_2', \n",
    "           'm5_3', 'm5_4', 'm5_5', 'm5_6', \n",
    "           'm5_7', 'm5_8', 'm5_9']]\n",
    "label = df['label']\n",
    "\n",
    "# 初始化结果列表\n",
    "results = []\n",
    "\n",
    "# 多轮实验\n",
    "for iteration in range(20):\n",
    "    print(f'---------- Iteration {iteration+1} ----------')\n",
    "\n",
    "    # 划分训练与测试集\n",
    "    train_x, test_x, train_y, test_y = train_test_split(df7, label, test_size=0.2, stratify=label, random_state=iteration)\n",
    "\n",
    "    # 轻度过采样：让少数类达到多数类的80%\n",
    "    ros = RandomOverSampler(sampling_strategy=0.75, random_state=iteration)\n",
    "    train_x_res, train_y_res = ros.fit_resample(train_x, train_y)\n",
    "\n",
    "    # 根据过采样后的训练集重新计算 scale_pos_weight\n",
    "    scale_weight = train_y_res.value_counts()[0] / train_y_res.value_counts()[1]\n",
    "\n",
    "    # 超参数网格\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 150],\n",
    "        'max_depth': [5, 10],\n",
    "        'min_child_weight': [2, 4],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0]\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_weight\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=iteration)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    grid.fit(train_x_res, train_y_res)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(test_x)\n",
    "\n",
    "    results.append({\n",
    "        'Iteration': iteration + 1,\n",
    "        'Accuracy': round(accuracy_score(test_y, y_pred), 3),\n",
    "        'Recall': round(recall_score(test_y, y_pred), 3),\n",
    "        'F1 Score': round(f1_score(test_y, y_pred), 3),\n",
    "        'Precision': round(precision_score(test_y, y_pred), 3),\n",
    "        'Best Params': grid.best_params_\n",
    "    })\n",
    "\n",
    "# 保存结果\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('MMTD_gossipcop_weighted_oversample_5fold.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bf560-0d1c-4f7c-bf29-8361042846b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
